---
title: Violation of Proportional Odds is Not Fatal
author: Frank Harrell
date: '2020-09-20'
modified: '2021-03-13'
slug: po
categories: []
tags:
  - 2020
  - accuracy-score
  - RCT
  - regression
  - hypothesis testing
  - metrics
link-citations: yes
summary: Many researchers worry about violations of the proportional hazards assumption when comparing treatments in a randomized study.  Besides the fact that this frequently makes them turn to a much worse approach, the harm done by violations of the proportional odds assumption usually do not prevent the proportional odds model from providing a reasonable treatment effect assessment.
header:
  caption: ''
  image: ''
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<p class="rquote">
Clearly, the dependence of the proportional odds model on the assumption of proportionality can be overstressed. Suppose that two different statisticians would cut the same three-point scale at different cut points. It is hard to see how anybody who could accept either dichotomy could object to the compromise answer produced by the proportional odds model. — <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3603">Stephen Senn</a>
</p>
<p class="rquote">
Companion article: <a href="https://fharrell.com/post/wpo">If You Like the Wilcoxon Test You Must Like the Proportional Odds Model</a>
</p>
<div id="background" class="section level1">
<h1>Background</h1>
<p>The Wilcoxon Mann-Whitney (WMW) two-sample rank-sum test for comparing two groups on a continuous or ordinal outcome variable Y is a much liked statistical test, for good reason. It is robust to ‘outliers’ and is virtually as powerful as the two-sample t-test even if that test’s normality assumption holds. The k-sample generalization of the Wilcoxon test is the Kruskal-Wallis test, and a regression model generalization of both the Wilcoxon and Kruskal-Wallis tests is the proportional odds (PO) semiparametric logistic regression model for ordinal or continuous Y. The PO model has advantages over the WMW and Kruskal-Wallis tests in that it can handle covariate adjustment and allow for arbitrarily many ties in Y all the way to the case where Y is binary, at which point the PO model is the binary logistic model. The PO model also provides various useful estimates such as quantiles, means, and exceedance probabilities.</p>
<p>The WMW test involves the Mann-Whitney U statistic. U statistics were developed by <a href="https://projecteuclid.org/euclid.aoms/1177730196">Hoeffding</a> in 1948. A U statistic is an average over all possible pairs (or triplets, quadruplets, etc.) of observations of a <em>kernel</em>. For WMW the kernel is a 0/1 indicator signifying whether a randomly chosen observation from treatment group B is larger than a randomly chosen observation in group A. So the Wilcoxon test tests whether values of Y in group B tend to be larger than those in group A, i.e., tests for <em>stochastic ordering</em>. The U statistic summary measures the degree to which Y values from B are separated from those in A, with a value of 0.5 indicating no tendency for values if B to be greater or less than those in A. This statistic is a <em>concordance probability</em>, also called a <span class="math inline">\(c\)</span>-index. It is a measure of discrimination that is also equal to the area under a receiver operating characteristic curve. When treatments are denoted A and B, the <span class="math inline">\(c\)</span>-index is the probability that a randomly chosen patient receiving treatment B has a value of Y that exceeds that of a randomly chosen patient receiving treatment A. It is a natural unitless parameter for quantifying treatment effect on an ordinal or continuous outcome.</p>
<p>For binary, ordinal, or continuous variables X and Y, rank correlation coefficients are excellent measures for quantifying the degree of association between X and Y. When X is binary such as a treatment indicator, rank correlation measures the separation of Y values that is apparently explained by treatment group X. The rank correlation coefficient that corresponds to the Wilcoxon test is Somers’ <span class="math inline">\(D_{yx}\)</span> where the order of <span class="math inline">\(yx\)</span> signifies that ties in x are ignored and ties in y are not. For comparing treatments A and B we do not draw a random pair of observations from the same treatment, but only consider observations in different treatment groups (drop ties in x). In the binary outcome situation, on the other hand, we use <span class="math inline">\(D_{xy}\)</span>.</p>
<p><span class="math inline">\(D_{yx}\)</span> is 0 if the <span class="math inline">\(c\)</span>-index equals 0.5, i.e., there is no separation in Y values that can be explained by the treatment X. When c=0, meaning that all Y values for treatment A are larger than all Y values for B, <span class="math inline">\(D_{yx}=-1\)</span>, and when c=1, meaning that all Y values for treatment B are larger than all values for treatment A (perfect separation in the opposite direction as when c=0), <span class="math inline">\(D_{yx}=1\)</span>. There is a perfect correspondence between the MWM test, the concordance probability c, and Somers’ <span class="math inline">\(D_{yx}\)</span>, i.e., you can perfectly compute the other two given any one of these indexes. <span class="math inline">\(D_{yx}\)</span> is also the difference between the probability of concordance of X and Y and the probability of discordance.</p>
<p>There is also a 1-1 relationship between the Wilcoxon statistic and Spearman’s <span class="math inline">\(\rho\)</span> rank correlation. <span class="math inline">\(\rho\)</span> is a different metric than <span class="math inline">\(D_{yx}\)</span> but it is possible to convert from one to the other for a given dataset.</p>
<p>For the normal case, i.e., when using a two-sample <span class="math inline">\(t\)</span>-test or a linear model with a true treatment mean difference of <span class="math inline">\(\delta\)</span> and constant standard deviation of <span class="math inline">\(\sigma\)</span>, the standard deviation of the difference between a randomly chosen response on treatment B and one from A is <span class="math inline">\(\sigma \sqrt{2}\)</span> since the variances sum. The concordance probability <span class="math inline">\(c\)</span> in this special case is
<span class="math display">\[\begin{array}{lll}
P(Y_{B} &gt; Y_{A}) &amp;=&amp; P(Y_{B} - Y_{A} &gt; 0) \\
&amp;=&amp; P(Y_{B} - Y_{A} - \delta &gt; - \delta) \\
&amp;=&amp; P(Y_{B} - Y_{A} - \delta &lt; \delta) \\
&amp;=&amp; P(\frac{Y_{B} - Y_{A} - \delta}{\sigma \sqrt{2}} &lt; \frac{\delta}{\sigma \sqrt{2}}) \\
&amp;=&amp; P(Z &lt; \frac{\delta}{\sigma \sqrt{2}})
\end{array}\]</span>
where <span class="math inline">\(Z\)</span> is a standard Normal(0,1) variable. If we let the standardized treatment difference (the difference in <span class="math inline">\(\sigma\)</span> units) be denoted by <span class="math inline">\(\Delta\)</span> (often called Cohen’s <span class="math inline">\(d\)</span>), <span class="math inline">\(c = \Phi(\frac{\Delta}{\sqrt{2}})\)</span> where <span class="math inline">\(\Phi\)</span> denotes the standard normal cumulative distribution function.</p>
</div>
<div id="relationship-between-log-odds-ratio-and-rank-correlation" class="section level1">
<h1>Relationship Between Log Odds Ratio and Rank Correlation</h1>
<p>We use concordance probabilities or <span class="math inline">\(D_{yx}\)</span> without regard to the proportional odds (PO) assumption, and find them quite reasonable summaries of the degree to which Y increases when X increases. How then is the <span class="math inline">\(c\)</span>-index related to the log odds ratio in the PO model whether or not the PO assumption is satisfied? There is no closed form solution for the maximum likelihood estimate <span class="math inline">\(\hat{\beta}\)</span> for treatment group in the PO model, but we can run a large number of simulations to describe the extent to which <span class="math inline">\(\hat{\beta}\)</span> tells us the same thing as <span class="math inline">\(c\)</span> or Somers’ rank correlation even when PO does not hold. Consider samples sizes of 10, 11, …, 100 and 1000 and take 20 random samples at each sample size. For each sample, take the treatment assignment <code>x</code> as a random sample of 0 and 1 each with probability 0.5, and take the Y values as a sample with replacement of the integers 1, …, n when the sample size is n. Sampling with replacement will create a variety of ties in the data. For each sample compute the concordance probability <code>cstat</code> and the maximum likelihood estimate for the <code>x</code> effect in the PO model. Because of the presence of sufficient randomness in the data generated (including large observed treatment effects in samples where there is none in the population), proportional odds will be apparently violated many times as judged by sample values.</p>
<pre class="r"><code>ns &lt;- c(10:100, 1000)
d &lt;- expand.grid(n = ns, m=1 : 20)
N &lt;- nrow(d)
cstat &lt;- beta &lt;- numeric(N)
set.seed(5)
rn &lt;- function(x) round(x, 3)
for(i in 1 : N) {
  n &lt;- d[i, &#39;n&#39;]
  x &lt;- sample(0 : 1, n, replace=TRUE)
  y &lt;- sample(1 : n, n, replace=TRUE)
  cstat[i] &lt;- somers2(y, x)[&#39;C&#39;]
  # eps: stricter convergence criterion
  b &lt;- coef(orm(y ~ x, eps=0.000001, maxit=25))
  beta[i] &lt;- b[length(b)]
    if(i == 3) {
      cat(&#39;Sample with worst approximation\nbeta=&#39;,
            rn(beta[i]), &#39;c=&#39;, rn(cstat[i]),
                &#39;\nbeta estimated from c:&#39;, rn(1.52 * qlogis(cstat[i])),
                &#39;\nc estimated from beta:&#39;, rn(plogis(beta[i] / 1.52)), &#39;\n&#39;)
        print(table(x, y))
        saveRDS(data.frame(x, y), &#39;/tmp/d.rds&#39;)
    }
}</code></pre>
<pre><code>Sample with worst approximation
beta= -4.538 c= 0.031 
beta estimated from c: -5.22 
c estimated from beta: 0.048 
   y
x   1 2 3 4 6 9 10 11 12
  0 0 0 0 0 1 0  1  1  1
  1 2 1 1 3 0 1  0  0  0</code></pre>
<pre class="r"><code>plot(cstat, beta)
plot(qlogis(cstat), beta)</code></pre>
<p><img src="/post/po_files/figure-html/sim-1.png" width="672" /><img src="/post/po_files/figure-html/sim-2.png" width="672" /></p>
<p>A very strong and linear relationship is found in the second graph above. I expected the second graph to be more linear, because the logit transformation of the concordance probability has an unlimited range just as the log odds ratio does. We can approximate <span class="math inline">\(\hat{\beta}\)</span> with a linear model in the logit of <span class="math inline">\(c\)</span>:</p>
<pre class="r"><code>f &lt;- ols(beta ~ qlogis(cstat))
f</code></pre>
<p><strong>Linear Regression Model</strong></p>
<pre>
 ols(formula = beta ~ qlogis(cstat))
 </pre>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Model Likelihood<br>Ratio Test
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Discrimination<br>Indexes
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
Obs 1840
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
LR χ<sup>2</sup> 10037.60
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>R</i><sup>2</sup> 0.996
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
σ 0.0396
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
d.f. 1
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>R</i><sup><span style="font-size: 70%;">2</span></sup><sub style='position: relative; left: -.47em; bottom: -.4em;'><span style="font-size: 70%;">adj</span></sub> 0.996
</td>
</tr>
<tr>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
d.f. 1838
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
Pr(&gt;χ<sup>2</sup>) 0.0000
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
<i>g</i> 0.636
</td>
</tr>
</tbody>
</table>
<p>Residuals</p>
<pre>
        Min         1Q     Median         3Q        Max 
 -0.5527344 -0.0036478 -0.0004424  0.0022669  0.6742581 
 </pre>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<th style="border-bottom: 1px solid grey; font-weight: 900; border-top: 2px solid grey; min-width: 7em; text-align: center;">
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
β
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
S.E.
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
<i>t</i>
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
Pr(&gt;|<i>t</i>|)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="min-width: 7em; text-align: left;">
Intercept
</td>
<td style="min-width: 7em; text-align: right;">
 0.0003
</td>
<td style="min-width: 7em; text-align: right;">
 0.0009
</td>
<td style="min-width: 7em; text-align: right;">
0.37
</td>
<td style="min-width: 7em; text-align: right;">
0.7080
</td>
</tr>
<tr>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: left;">
cstat
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
 1.5179
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
 0.0023
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
654.38
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
&lt;0.0001
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>r1 &lt;- abs(beta - fitted(f))
r2 &lt;- abs(cstat - plogis(beta / 1.52))
mae  &lt;- rn(mean(r1))
cmae &lt;- rn(mean(r2))
i    &lt;- which.max(r1)
cat(&#39;&lt;small&gt;Maximum discrepency occurred in sample&#39;, i, &#39;&lt;/small&gt;\n&#39;)</code></pre>
<p><small>Maximum discrepency occurred in sample 3 </small></p>
<p>We see that <span class="math inline">\(\hat{\beta}\)</span> is very close to <span class="math inline">\(1.52 \times \mathrm{logit}(c)\)</span>, or inverting the equation we get <span class="math inline">\(c = \frac{1}{1 + \exp(-\hat{\beta} / 1.52)}\)</span>. The quality of the approximation is given by <span class="math inline">\(R^2\)</span>=0.996 or by a mean absolute prediction error for <span class="math inline">\(\hat{\beta}\)</span> of 0.012. Predicting <span class="math inline">\(c\)</span> from <span class="math inline">\(\hat{\beta}\)</span> the mean absolute prediction error is 0.002.</p>
<p>Here is a graph that allows easy conversion from one metric to another. The axes are, in order from top to bottom, the standardized difference in means <span class="math inline">\(\Delta\)</span> if the response Y were to have a normal distribution (treatment regression coefficient in a linear model divided by the residual standard deviation), the log odds ratio <span class="math inline">\(\hat{\beta}\)</span> (treatment regression coefficient in a proportional odds model), the <span class="math inline">\(c\)</span>-index (probability of treatment B having higher outcomes than treatment A), and odds ratio <span class="math inline">\(e^{\hat{\beta}}\)</span> (anti-log of <span class="math inline">\(\hat{\beta}\)</span>).</p>
<pre class="r"><code>par(mar=c(3,.5,1,.5))
sdif   &lt;- function(x, y) setdiff(round(x, 4), round(y, 4))
Delta  &lt;- seq(-3, 3, by=1)
Delta2 &lt;- sdif(seq(-3, 3, by=0.1), Delta)
conc   &lt;- c(.01,.05,seq(.1,.9,by=.1),.95,.99)
conc2  &lt;- sdif(seq(0.04, 0.96, by=0.01), conc)
or     &lt;- c(0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 50)
or2    &lt;- sdif(c(seq(0.01, 0.5, by=0.01), seq(.5, 3, by=0.1), seq(3, 5, by=0.5),
                  6:20, 30, 40, 50), or)
lor    &lt;- seq(-5, 5, by=1)
lor2   &lt;- sdif(seq(-5, 5, by=0.1), lor)
f      &lt;- function(conc) 1.52 * qlogis(conc)
g      &lt;- function(z) f(pnorm(z / sqrt(2)))

plot.new()
par(usr=c(-5,5,-1.04,1.04))
par(mgp=c(1.5,.5,0))

axis(1, at=g(Delta), labels=as.character(Delta),
     tcl=.5, mgp=c(-3,-1.7,0), line=-7)
axis(1, at=g(Delta2), tcl=.25, col.ticks=gray(.7), labels=FALSE, line=-7)
title(xlab=expression(Delta), line=-10)
axis(1, at=lor, as.character(lor),
     tcl=-.5, mgp=c(-3, 0.8, 0), line=-7)</code></pre>
<pre class="r"><code>axis(1, at=lor2, tcl=-.25, col.ticks=gray(.7), labels=FALSE, line=-7)
title(xlab=expression(beta), line=-4.5)

     
axis(1, at=log(or),  labels=as.character(or))
axis(1, at=log(or2), tcl=-.25, col.ticks=gray(.7), labels=FALSE)
title(xlab=&#39;Odds Ratio&#39;)
axis(1, at=f(conc), labels=as.character(conc), 
     tcl=.5, mgp=c(-3,-1.7,0))
axis(1, at=f(conc2), tcl=.25, col.ticks=gray(.7), labels=FALSE)
title(xlab=&#39;P(B &gt; A)&#39;, mgp=c(-3,-1.7,0))</code></pre>
<p><img src="/post/po_files/figure-html/nom-1.png" width="672" /></p>
<p>As discussed in <a href="https://www.onlinelibrary.wiley.com/doi/10.1111/biom.12565">Agresti and Kateri</a> (see also <a href="https://onlinelibrary.wiley.com/doi/10.1111/stan.12130">Agresti and Tarantola</a>), even with adjustment for covariates, if one compares a random patient on treatment B with a random patient on treatment A, with both patients having the same covariate values, the concordance probability is approximately <span class="math inline">\(\frac{1}{1 + \exp{(-\beta/\sqrt{2})}}\)</span> (this is exact for probit ordinal regression but not for logistic ordinal regression) whereas our better approximation replaces <span class="math inline">\(\sqrt{2} =\)</span> 1.41 with 1.52.</p>
</div>
<div id="example" class="section level1">
<h1>Example</h1>
<p>Consider an analysis of the relationship between cancer treatment (cisplatin vs. no cisplatin) and severity of nausea (6 levels) as analyzed in <a href="https://www.jstor.org/stable/2347760">Peterson and Harrell 1990</a>. First compute the exact concordance probability, which is a simple linear translation of the WMW statistic. Note that <span class="math inline">\(D_{xy}\)</span> in the output is really <span class="math inline">\(D_{yx}\)</span> since the order of arguments to the <code>somers2</code> function was reversed.</p>
<pre class="r"><code>d0 &lt;- data.frame(tx=0, y=c(rep(0, 43), rep(1, 39), rep(2, 13), rep(3, 22),
                           rep(4, 15), rep(5, 29)))
d1 &lt;- data.frame(tx=1, y=c(rep(0, 7), rep(1, 7), rep(2, 3), rep(3, 12),
                           rep(4, 15), rep(5, 14)))
d &lt;- rbind(d0, d1)
d$tx &lt;- factor(d$tx, 0:1, c(&#39;No cisplatin&#39;, &#39;cisplatin&#39;))
dd &lt;- datadist(d); options(datadist=&#39;dd&#39;)
with(d, table(tx, y))</code></pre>
<pre><code>              y
tx              0  1  2  3  4  5
  No cisplatin 43 39 13 22 15 29
  cisplatin     7  7  3 12 15 14</code></pre>
<pre class="r"><code>cindex &lt;- with(d, somers2(y, as.numeric(tx) - 1))
cindex</code></pre>
<pre><code>          C         Dxy           n     Missing 
  0.6472478   0.2944956 219.0000000   0.0000000 </code></pre>
<pre class="r"><code>cexact &lt;- cindex[&#39;C&#39;]</code></pre>
<p>Now use the <code>rms</code> package <code>orm</code> function to compute the overall cisplatin : no cisplatin log odds ratio for effect on severity of nausea.</p>
<pre class="r"><code>f &lt;- orm(y ~ tx, data=d)
f</code></pre>
<p><strong>Logistic (Proportional Odds) Ordinal Regression Model</strong></p>
<pre>
 orm(formula = y ~ tx, data = d)
 </pre>
<p>Frequencies of Responses</p>
<pre>
  0  1  2  3  4  5 
 50 46 16 34 30 43 
 </pre>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Model Likelihood<br>Ratio Test
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Discrimination<br> Indexes
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; border-right: 1px solid black; text-align: center;">
Rank Discrim.<br>Indexes
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
Obs 219
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
LR χ<sup>2</sup> 11.42
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>R</i><sup>2</sup> 0.052
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
ρ 0.229
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
Distinct <i>Y</i> 6
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
d.f. 1
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>g</i> 0.356
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
<i>Y</i><sub>0.5</sub> 2
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
Pr(&gt;χ<sup>2</sup>) 0.0007
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<i>g</i><sub>r</sub> 1.428
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
</td>
</tr>
<tr>
<td style="min-width: 9em; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
max |∂log <i>L</i>/∂β| 1×10<sup>-6</sup>
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
Score χ<sup>2</sup> 11.49
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
<span style="text-decoration: overline">|Pr(<i>Y</i> ≥ median)-½|</span> 0.059
</td>
<td style="min-width: 9em; border-right: 1px solid black; text-align: center;">
</td>
</tr>
<tr>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-left: 1px solid black; border-right: 1px solid black; text-align: center;">
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
Pr(&gt;χ<sup>2</sup>) 0.0007
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
</td>
<td style="min-width: 9em; border-bottom: 2px solid grey; border-right: 1px solid black; text-align: center;">
</td>
</tr>
</tbody>
</table>
<table class="gmisc_table" style="border-collapse: collapse; margin-top: 1em; margin-bottom: 1em;">
<thead>
<tr>
<th style="border-bottom: 1px solid grey; font-weight: 900; border-top: 2px solid grey; min-width: 7em; text-align: center;">
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
β
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
S.E.
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
Wald <i>Z</i>
</th>
<th style="font-weight: 900; border-bottom: 1px solid grey; border-top: 2px solid grey; text-align: right;">
Pr(&gt;|<i>Z</i>|)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="min-width: 7em; text-align: left;">
y≥1
</td>
<td style="min-width: 7em; text-align: right;">
  1.0189
</td>
<td style="min-width: 7em; text-align: right;">
 0.1717
</td>
<td style="min-width: 7em; text-align: right;">
5.93
</td>
<td style="min-width: 7em; text-align: right;">
&lt;0.0001
</td>
</tr>
<tr>
<td style="min-width: 7em; text-align: left;">
y≥2
</td>
<td style="min-width: 7em; text-align: right;">
  0.0118
</td>
<td style="min-width: 7em; text-align: right;">
 0.1546
</td>
<td style="min-width: 7em; text-align: right;">
0.08
</td>
<td style="min-width: 7em; text-align: right;">
0.9390
</td>
</tr>
<tr>
<td style="min-width: 7em; text-align: left;">
y≥3
</td>
<td style="min-width: 7em; text-align: right;">
 -0.2996
</td>
<td style="min-width: 7em; text-align: right;">
 0.1569
</td>
<td style="min-width: 7em; text-align: right;">
-1.91
</td>
<td style="min-width: 7em; text-align: right;">
0.0562
</td>
</tr>
<tr>
<td style="min-width: 7em; text-align: left;">
y≥4
</td>
<td style="min-width: 7em; text-align: right;">
 -0.9868
</td>
<td style="min-width: 7em; text-align: right;">
 0.1718
</td>
<td style="min-width: 7em; text-align: right;">
-5.75
</td>
<td style="min-width: 7em; text-align: right;">
&lt;0.0001
</td>
</tr>
<tr>
<td style="min-width: 7em; text-align: left;">
y≥5
</td>
<td style="min-width: 7em; text-align: right;">
 -1.7254
</td>
<td style="min-width: 7em; text-align: right;">
 0.1994
</td>
<td style="min-width: 7em; text-align: right;">
-8.66
</td>
<td style="min-width: 7em; text-align: right;">
&lt;0.0001
</td>
</tr>
<tr>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: left;">
tx=cisplatin
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
  0.9112
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
 0.2714
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
3.36
</td>
<td style="min-width: 7em; border-bottom: 2px solid grey; text-align: right;">
0.0008
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>b &lt;- coef(f)[&#39;tx=cisplatin&#39;]
cest &lt;- plogis(b / 1.52)</code></pre>
<p>The concordance probability estimated from the average log odds ratio is 0.646 which is to be compared with the exact value of 0.647. The agreement is excellent despite non-PO, which is analyzed formally using a partial PO model <a href="https://hbiostat.org/R/rmsb/blrm.html#partial-proportional-odds-model">here</a> as well as in the Peterson and Harrell paper.</p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>When PO does not hold, the odds ratio from the proportional odds model represents a kind of average odds ratio, and there is an almost one-to-one relationship between the odds ratio (anti-log of <span class="math inline">\(\hat{\beta}\)</span>) and the concordance probability <span class="math inline">\(c\)</span> (which is a simple translation of the Wilcoxon statistic). No model fits data perfectly, but as Stephen Senn stated in the quote that opened this article, the approximation offered by the PO model remains quite useful. And a unified PO model analysis is decidedly better than turning to inefficient and arbitrary analyses of dichotomized values of Y.</p>
<p>If you like the Wilcoxon test for comparing an ordinal response variable Y across treatments, or you like standard rank correlation measures for describing the strength of association between X and Y, you must like the PO model for summarizing treatment effects on ordinal (or continuous) Y. In a clinical trial we are interested in estimating the degree to which a treatment favorably redistributes patients across levels of Y in order to get a unified analysis of how a treatment improves patient outcomes. The PO model does that. And the natural parameter, concordance probability P(B &gt; A), is a simple function of the PO model’s treatment odds ratio.</p>
<p>The place where a serious departure from the parallelism/PO assumption makes a large difference is in estimating treatment effects on individual outcome levels. For example, an overall odds ratio indicating that treatment benefits patients on an array of nonfatal outcomes may be in the opposite direction of how the treatment affects mortality. Though the overall average treatment effect estimated by assuming PO may rightfully claim a positive net clinical benefit of treatment, one can get a different picture when estimating the mortality effect ignoring all the other outcomes. This may be addressed using the <em>partial proportional odds model</em> of <a href="https://www.jstor.org/stable/2347760">Peterson and Harrell, 1990</a> as implemented <a href="https://hbiostat.org/R/rmsb/blrm.html">here</a> and discussed in the COVID-19 context <a href="https://hbiostat.org/proj/covid19/statdesign.html#univariate-ordinal-outcome">here</a>.</p>
</div>
